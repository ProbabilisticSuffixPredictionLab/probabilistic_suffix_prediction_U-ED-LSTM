{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:42:11.872177Z",
     "iopub.status.busy": "2025-04-25T08:42:11.872089Z",
     "iopub.status.idle": "2025-04-25T08:42:12.665133Z",
     "shell.execute_reply": "2025-04-25T08:42:12.664806Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, '../..')\n",
    "sys.path.insert(0, '../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helpdesk_all_normal_3_test.pkl\t helpdesk_all_normal_3_val.pkl\n",
      "helpdesk_all_normal_3_train.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../../../../ProbabilisticSuffixPredictionLab/risk_controlled_proactive_conformance_checking_dev/data/encoded_data/Helpdesk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:42:12.666637Z",
     "iopub.status.busy": "2025-04-25T08:42:12.666506Z",
     "iopub.status.idle": "2025-04-25T08:42:13.170208Z",
     "shell.execute_reply": "2025-04-25T08:42:13.169793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'event_log_loader.new_event_log_loader.EventLogDataset'>\n",
      "<class 'event_log_loader.new_event_log_loader.EventLogDataset'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/PSPLab/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-4nDU3HwC/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator OrdinalEncoder from version 1.5.2 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/PSPLab/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-4nDU3HwC/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator SimpleImputer from version 1.5.2 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/PSPLab/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-4nDU3HwC/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.2 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/PSPLab/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-4nDU3HwC/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator OrdinalEncoder from version 1.5.2 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/PSPLab/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-4nDU3HwC/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator SimpleImputer from version 1.5.2 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/PSPLab/.local/share/virtualenvs/Probabilistic_Suffix_Prediction_U-ED-LSTM_-4nDU3HwC/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.2 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Path to your pickle file (saved with torch.save)\n",
    "file_path_train = '../../../../../../ProbabilisticSuffixPredictionLab/risk_controlled_proactive_conformance_checking_dev/data/encoded_data/Helpdesk/helpdesk_all_normal_3_train.pkl'\n",
    "# Load the dataset using torch.load\n",
    "helpdesk_train_dataset = torch.load(file_path_train, weights_only=False)\n",
    "# Check the type of the loaded dataset\n",
    "print(type(helpdesk_train_dataset))  # Should output something like <class 'torch.utils.data.dataset.TensorDataset'>\n",
    "\n",
    "# Path to your pickle file (saved with torch.save)\n",
    "file_path_val = '../../../../../../ProbabilisticSuffixPredictionLab/risk_controlled_proactive_conformance_checking_dev/data/encoded_data/Helpdesk/helpdesk_all_normal_3_val.pkl'\n",
    "# Load the dataset using torch.load\n",
    "helpdesk_val_dataset = torch.load(file_path_val, weights_only=False)\n",
    "# Check the type of the loaded dataset\n",
    "print(type(helpdesk_val_dataset))  # Should output something like <class 'torch.utils.data.dataset.TensorDataset'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:42:13.191720Z",
     "iopub.status.busy": "2025-04-25T08:42:13.191548Z",
     "iopub.status.idle": "2025-04-25T08:42:13.194814Z",
     "shell.execute_reply": "2025-04-25T08:42:13.194483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Activity', 16, {'Assign seriousness': 1, 'Closed': 2, 'Create SW anomaly': 3, 'DUPLICATE': 4, 'EOS': 5, 'INVALID': 6, 'Insert ticket': 7, 'RESOLVED': 8, 'Require upgrade': 9, 'Resolve SW anomaly': 10, 'Resolve ticket': 11, 'Schedule intervention': 12, 'Take in charge ticket': 13, 'VERIFIED': 14, 'Wait': 15}), ('Resource', 24, {'EOS': 1, 'Value 1': 2, 'Value 10': 3, 'Value 11': 4, 'Value 12': 5, 'Value 13': 6, 'Value 14': 7, 'Value 15': 8, 'Value 16': 9, 'Value 17': 10, 'Value 18': 11, 'Value 19': 12, 'Value 2': 13, 'Value 20': 14, 'Value 21': 15, 'Value 22': 16, 'Value 3': 17, 'Value 4': 18, 'Value 5': 19, 'Value 6': 20, 'Value 7': 21, 'Value 8': 22, 'Value 9': 23}), ('VariantIndex', 184, {'1.0': 1, '10.0': 2, '100.0': 3, '103.0': 4, '104.0': 5, '105.0': 6, '107.0': 7, '109.0': 8, '11.0': 9, '110.0': 10, '112.0': 11, '113.0': 12, '114.0': 13, '115.0': 14, '117.0': 15, '118.0': 16, '12.0': 17, '120.0': 18, '121.0': 19, '122.0': 20, '123.0': 21, '124.0': 22, '125.0': 23, '126.0': 24, '127.0': 25, '129.0': 26, '13.0': 27, '130.0': 28, '131.0': 29, '134.0': 30, '135.0': 31, '137.0': 32, '138.0': 33, '139.0': 34, '14.0': 35, '140.0': 36, '141.0': 37, '143.0': 38, '144.0': 39, '145.0': 40, '147.0': 41, '149.0': 42, '15.0': 43, '150.0': 44, '151.0': 45, '152.0': 46, '153.0': 47, '154.0': 48, '155.0': 49, '156.0': 50, '157.0': 51, '158.0': 52, '16.0': 53, '162.0': 54, '163.0': 55, '164.0': 56, '165.0': 57, '167.0': 58, '168.0': 59, '169.0': 60, '17.0': 61, '170.0': 62, '171.0': 63, '172.0': 64, '173.0': 65, '174.0': 66, '175.0': 67, '176.0': 68, '178.0': 69, '179.0': 70, '18.0': 71, '180.0': 72, '181.0': 73, '182.0': 74, '183.0': 75, '188.0': 76, '19.0': 77, '192.0': 78, '193.0': 79, '194.0': 80, '195.0': 81, '197.0': 82, '199.0': 83, '2.0': 84, '20.0': 85, '200.0': 86, '202.0': 87, '203.0': 88, '204.0': 89, '205.0': 90, '207.0': 91, '208.0': 92, '21.0': 93, '211.0': 94, '212.0': 95, '213.0': 96, '214.0': 97, '217.0': 98, '22.0': 99, '220.0': 100, '222.0': 101, '225.0': 102, '226.0': 103, '23.0': 104, '24.0': 105, '25.0': 106, '26.0': 107, '27.0': 108, '28.0': 109, '29.0': 110, '3.0': 111, '30.0': 112, '31.0': 113, '32.0': 114, '33.0': 115, '34.0': 116, '35.0': 117, '36.0': 118, '37.0': 119, '38.0': 120, '39.0': 121, '4.0': 122, '40.0': 123, '41.0': 124, '42.0': 125, '43.0': 126, '44.0': 127, '45.0': 128, '46.0': 129, '47.0': 130, '48.0': 131, '49.0': 132, '5.0': 133, '50.0': 134, '51.0': 135, '52.0': 136, '53.0': 137, '54.0': 138, '55.0': 139, '56.0': 140, '57.0': 141, '58.0': 142, '59.0': 143, '6.0': 144, '60.0': 145, '61.0': 146, '62.0': 147, '63.0': 148, '64.0': 149, '65.0': 150, '66.0': 151, '67.0': 152, '68.0': 153, '69.0': 154, '7.0': 155, '70.0': 156, '71.0': 157, '72.0': 158, '73.0': 159, '74.0': 160, '75.0': 161, '76.0': 162, '77.0': 163, '78.0': 164, '79.0': 165, '8.0': 166, '81.0': 167, '83.0': 168, '84.0': 169, '85.0': 170, '86.0': 171, '87.0': 172, '88.0': 173, '89.0': 174, '9.0': 175, '90.0': 176, '91.0': 177, '93.0': 178, '94.0': 179, '95.0': 180, '97.0': 181, '99.0': 182, nan: 183}), ('seriousness', 3, {'EOS': 1, 'Value 1': 2}), ('customer', 370, {'EOS': 1, 'Value 1': 2, 'Value 10': 3, 'Value 100': 4, 'Value 101': 5, 'Value 102': 6, 'Value 103': 7, 'Value 104': 8, 'Value 105': 9, 'Value 106': 10, 'Value 107': 11, 'Value 108': 12, 'Value 11': 13, 'Value 110': 14, 'Value 111': 15, 'Value 112': 16, 'Value 113': 17, 'Value 114': 18, 'Value 115': 19, 'Value 116': 20, 'Value 117': 21, 'Value 118': 22, 'Value 119': 23, 'Value 12': 24, 'Value 120': 25, 'Value 121': 26, 'Value 122': 27, 'Value 123': 28, 'Value 124': 29, 'Value 125': 30, 'Value 126': 31, 'Value 127': 32, 'Value 129': 33, 'Value 13': 34, 'Value 131': 35, 'Value 132': 36, 'Value 133': 37, 'Value 134': 38, 'Value 135': 39, 'Value 136': 40, 'Value 137': 41, 'Value 138': 42, 'Value 139': 43, 'Value 14': 44, 'Value 140': 45, 'Value 141': 46, 'Value 142': 47, 'Value 143': 48, 'Value 144': 49, 'Value 145': 50, 'Value 146': 51, 'Value 147': 52, 'Value 148': 53, 'Value 149': 54, 'Value 15': 55, 'Value 150': 56, 'Value 151': 57, 'Value 152': 58, 'Value 153': 59, 'Value 154': 60, 'Value 155': 61, 'Value 156': 62, 'Value 157': 63, 'Value 158': 64, 'Value 16': 65, 'Value 160': 66, 'Value 161': 67, 'Value 162': 68, 'Value 163': 69, 'Value 164': 70, 'Value 165': 71, 'Value 166': 72, 'Value 167': 73, 'Value 168': 74, 'Value 169': 75, 'Value 17': 76, 'Value 171': 77, 'Value 172': 78, 'Value 173': 79, 'Value 174': 80, 'Value 175': 81, 'Value 176': 82, 'Value 177': 83, 'Value 178': 84, 'Value 179': 85, 'Value 18': 86, 'Value 180': 87, 'Value 181': 88, 'Value 182': 89, 'Value 183': 90, 'Value 184': 91, 'Value 185': 92, 'Value 186': 93, 'Value 187': 94, 'Value 188': 95, 'Value 189': 96, 'Value 19': 97, 'Value 190': 98, 'Value 191': 99, 'Value 192': 100, 'Value 193': 101, 'Value 194': 102, 'Value 195': 103, 'Value 196': 104, 'Value 197': 105, 'Value 198': 106, 'Value 199': 107, 'Value 2': 108, 'Value 20': 109, 'Value 200': 110, 'Value 201': 111, 'Value 202': 112, 'Value 203': 113, 'Value 204': 114, 'Value 205': 115, 'Value 206': 116, 'Value 207': 117, 'Value 208': 118, 'Value 209': 119, 'Value 21': 120, 'Value 210': 121, 'Value 211': 122, 'Value 213': 123, 'Value 214': 124, 'Value 215': 125, 'Value 216': 126, 'Value 217': 127, 'Value 218': 128, 'Value 219': 129, 'Value 22': 130, 'Value 220': 131, 'Value 221': 132, 'Value 222': 133, 'Value 223': 134, 'Value 224': 135, 'Value 225': 136, 'Value 226': 137, 'Value 227': 138, 'Value 228': 139, 'Value 229': 140, 'Value 23': 141, 'Value 230': 142, 'Value 231': 143, 'Value 232': 144, 'Value 233': 145, 'Value 234': 146, 'Value 235': 147, 'Value 236': 148, 'Value 237': 149, 'Value 238': 150, 'Value 239': 151, 'Value 24': 152, 'Value 240': 153, 'Value 241': 154, 'Value 242': 155, 'Value 243': 156, 'Value 244': 157, 'Value 245': 158, 'Value 246': 159, 'Value 247': 160, 'Value 248': 161, 'Value 249': 162, 'Value 25': 163, 'Value 250': 164, 'Value 251': 165, 'Value 252': 166, 'Value 253': 167, 'Value 254': 168, 'Value 255': 169, 'Value 256': 170, 'Value 258': 171, 'Value 259': 172, 'Value 26': 173, 'Value 260': 174, 'Value 261': 175, 'Value 262': 176, 'Value 263': 177, 'Value 264': 178, 'Value 265': 179, 'Value 266': 180, 'Value 267': 181, 'Value 268': 182, 'Value 269': 183, 'Value 27': 184, 'Value 270': 185, 'Value 271': 186, 'Value 272': 187, 'Value 273': 188, 'Value 274': 189, 'Value 275': 190, 'Value 276': 191, 'Value 277': 192, 'Value 278': 193, 'Value 279': 194, 'Value 28': 195, 'Value 280': 196, 'Value 281': 197, 'Value 282': 198, 'Value 283': 199, 'Value 284': 200, 'Value 285': 201, 'Value 286': 202, 'Value 287': 203, 'Value 288': 204, 'Value 289': 205, 'Value 29': 206, 'Value 292': 207, 'Value 293': 208, 'Value 294': 209, 'Value 296': 210, 'Value 297': 211, 'Value 298': 212, 'Value 299': 213, 'Value 3': 214, 'Value 30': 215, 'Value 300': 216, 'Value 301': 217, 'Value 302': 218, 'Value 303': 219, 'Value 304': 220, 'Value 305': 221, 'Value 306': 222, 'Value 307': 223, 'Value 308': 224, 'Value 309': 225, 'Value 31': 226, 'Value 310': 227, 'Value 311': 228, 'Value 312': 229, 'Value 313': 230, 'Value 314': 231, 'Value 315': 232, 'Value 316': 233, 'Value 317': 234, 'Value 318': 235, 'Value 319': 236, 'Value 32': 237, 'Value 320': 238, 'Value 321': 239, 'Value 322': 240, 'Value 323': 241, 'Value 324': 242, 'Value 325': 243, 'Value 326': 244, 'Value 327': 245, 'Value 328': 246, 'Value 329': 247, 'Value 33': 248, 'Value 331': 249, 'Value 332': 250, 'Value 333': 251, 'Value 334': 252, 'Value 335': 253, 'Value 336': 254, 'Value 337': 255, 'Value 338': 256, 'Value 339': 257, 'Value 34': 258, 'Value 340': 259, 'Value 342': 260, 'Value 343': 261, 'Value 344': 262, 'Value 345': 263, 'Value 346': 264, 'Value 348': 265, 'Value 349': 266, 'Value 35': 267, 'Value 350': 268, 'Value 351': 269, 'Value 352': 270, 'Value 353': 271, 'Value 356': 272, 'Value 357': 273, 'Value 36': 274, 'Value 360': 275, 'Value 361': 276, 'Value 362': 277, 'Value 363': 278, 'Value 364': 279, 'Value 365': 280, 'Value 366': 281, 'Value 367': 282, 'Value 368': 283, 'Value 369': 284, 'Value 37': 285, 'Value 370': 286, 'Value 371': 287, 'Value 374': 288, 'Value 375': 289, 'Value 376': 290, 'Value 377': 291, 'Value 379': 292, 'Value 38': 293, 'Value 380': 294, 'Value 383': 295, 'Value 384': 296, 'Value 386': 297, 'Value 388': 298, 'Value 389': 299, 'Value 39': 300, 'Value 390': 301, 'Value 393': 302, 'Value 394': 303, 'Value 396': 304, 'Value 4': 305, 'Value 40': 306, 'Value 41': 307, 'Value 42': 308, 'Value 43': 309, 'Value 44': 310, 'Value 45': 311, 'Value 46': 312, 'Value 47': 313, 'Value 48': 314, 'Value 49': 315, 'Value 5': 316, 'Value 50': 317, 'Value 51': 318, 'Value 52': 319, 'Value 53': 320, 'Value 54': 321, 'Value 55': 322, 'Value 56': 323, 'Value 57': 324, 'Value 58': 325, 'Value 59': 326, 'Value 6': 327, 'Value 60': 328, 'Value 61': 329, 'Value 62': 330, 'Value 63': 331, 'Value 64': 332, 'Value 65': 333, 'Value 66': 334, 'Value 67': 335, 'Value 68': 336, 'Value 69': 337, 'Value 7': 338, 'Value 70': 339, 'Value 71': 340, 'Value 72': 341, 'Value 73': 342, 'Value 74': 343, 'Value 75': 344, 'Value 76': 345, 'Value 77': 346, 'Value 78': 347, 'Value 79': 348, 'Value 8': 349, 'Value 80': 350, 'Value 81': 351, 'Value 82': 352, 'Value 83': 353, 'Value 85': 354, 'Value 86': 355, 'Value 87': 356, 'Value 88': 357, 'Value 89': 358, 'Value 9': 359, 'Value 90': 360, 'Value 91': 361, 'Value 92': 362, 'Value 93': 363, 'Value 94': 364, 'Value 95': 365, 'Value 96': 366, 'Value 97': 367, 'Value 98': 368, 'Value 99': 369}), ('product', 23, {'EOS': 1, 'Value 1': 2, 'Value 10': 3, 'Value 11': 4, 'Value 12': 5, 'Value 13': 6, 'Value 14': 7, 'Value 15': 8, 'Value 16': 9, 'Value 17': 10, 'Value 18': 11, 'Value 19': 12, 'Value 2': 13, 'Value 20': 14, 'Value 21': 15, 'Value 3': 16, 'Value 4': 17, 'Value 5': 18, 'Value 6': 19, 'Value 7': 20, 'Value 8': 21, 'Value 9': 22}), ('responsible_section', 9, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5, 'Value 5': 6, 'Value 6': 7, 'Value 7': 8}), ('seriousness_2', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5}), ('service_level', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5}), ('service_type', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5}), ('support_section', 8, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5, 'Value 5': 6, 'Value 6': 7}), ('workgroup', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5})]\n",
      "[('case_elapsed_time', 1, {}), ('event_elapsed_time', 1, {}), ('day_in_week', 1, {}), ('seconds_in_day', 1, {})]\n",
      "Helpdesk (5) Categorical feature: Activity, Index position in categorical data list: 0\n",
      "Helpdesk (5) Total Amount of Category labels: 16\n",
      "Helpdesk (5) Categorical feature: Resource, Index position in categorical data list: 1\n",
      "Helpdesk (5) Total Amount of Category labels: 24\n",
      "Helpdesk (5) Categorical feature: VariantIndex, Index position in categorical data list: 2\n",
      "Helpdesk (5) Total Amount of Category labels: 184\n",
      "Helpdesk (5) Categorical feature: seriousness, Index position in categorical data list: 3\n",
      "Helpdesk (5) Total Amount of Category labels: 3\n",
      "Helpdesk (5) Categorical feature: customer, Index position in categorical data list: 4\n",
      "Helpdesk (5) Total Amount of Category labels: 370\n",
      "Helpdesk (5) Categorical feature: product, Index position in categorical data list: 5\n",
      "Helpdesk (5) Total Amount of Category labels: 23\n",
      "Helpdesk (5) Categorical feature: responsible_section, Index position in categorical data list: 6\n",
      "Helpdesk (5) Total Amount of Category labels: 9\n",
      "Helpdesk (5) Categorical feature: seriousness_2, Index position in categorical data list: 7\n",
      "Helpdesk (5) Total Amount of Category labels: 6\n",
      "Helpdesk (5) Categorical feature: service_level, Index position in categorical data list: 8\n",
      "Helpdesk (5) Total Amount of Category labels: 6\n",
      "Helpdesk (5) Categorical feature: service_type, Index position in categorical data list: 9\n",
      "Helpdesk (5) Total Amount of Category labels: 6\n",
      "Helpdesk (5) Categorical feature: support_section, Index position in categorical data list: 10\n",
      "Helpdesk (5) Total Amount of Category labels: 8\n",
      "Helpdesk (5) Categorical feature: workgroup, Index position in categorical data list: 11\n",
      "Helpdesk (5) Total Amount of Category labels: 6\n",
      "\n",
      "\n",
      "Helpdesk (5) Numerical feature: case_elapsed_time, Index position in categorical data list: 0\n",
      "Helpdesk (5) Amount Numerical: 1\n",
      "Helpdesk (5) Numerical feature: event_elapsed_time, Index position in categorical data list: 1\n",
      "Helpdesk (5) Amount Numerical: 1\n",
      "Helpdesk (5) Numerical feature: day_in_week, Index position in categorical data list: 2\n",
      "Helpdesk (5) Amount Numerical: 1\n",
      "Helpdesk (5) Numerical feature: seconds_in_day, Index position in categorical data list: 3\n",
      "Helpdesk (5) Amount Numerical: 1\n"
     ]
    }
   ],
   "source": [
    "# Helpdesk Dataset Categories, Features:\n",
    "helpdesk_all_categories = helpdesk_train_dataset.all_categories\n",
    "\n",
    "helpdesk_all_categories_cat = helpdesk_all_categories[0]\n",
    "print(helpdesk_all_categories_cat)\n",
    "\n",
    "helpdesk_all_categories_num = helpdesk_all_categories[1]\n",
    "print(helpdesk_all_categories_num)\n",
    "\n",
    "for i, cat in enumerate(helpdesk_all_categories_cat):\n",
    "     print(f\"Helpdesk (5) Categorical feature: {cat[0]}, Index position in categorical data list: {i}\")\n",
    "     print(f\"Helpdesk (5) Total Amount of Category labels: {cat[1]}\")\n",
    "print('\\n')    \n",
    "for i, num in enumerate(helpdesk_all_categories_num):\n",
    "     print(f\"Helpdesk (5) Numerical feature: {num[0]}, Index position in categorical data list: {i}\")\n",
    "     print(f\"Helpdesk (5) Amount Numerical: {num[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Features for Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:42:13.195762Z",
     "iopub.status.busy": "2025-04-25T08:42:13.195613Z",
     "iopub.status.idle": "2025-04-25T08:42:13.198008Z",
     "shell.execute_reply": "2025-04-25T08:42:13.197800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features encoder:  [['Activity', 'Resource', 'VariantIndex', 'seriousness', 'customer', 'product', 'responsible_section', 'seriousness_2', 'service_level', 'service_type', 'support_section', 'workgroup'], ['case_elapsed_time', 'event_elapsed_time', 'day_in_week', 'seconds_in_day']]\n",
      "Features decoder:  [['Activity', 'Resource'], ['case_elapsed_time', 'event_elapsed_time']]\n"
     ]
    }
   ],
   "source": [
    "# Create lists with name of Encoder features (input) and decoder features (input & output)\n",
    "\n",
    "# Encoder features:\n",
    "enc_feat_cat = []\n",
    "enc_feat_num = []\n",
    "for cat in helpdesk_all_categories_cat:\n",
    "    enc_feat_cat.append(cat[0])\n",
    "for num in helpdesk_all_categories_num:\n",
    "    enc_feat_num.append(num[0])\n",
    "enc_feat = [enc_feat_cat, enc_feat_num]\n",
    "print(\"Input features encoder: \", enc_feat)\n",
    "\n",
    "\"\"\"\n",
    "# Decoder features:\n",
    "dec_feat_cat = enc_feat_cat\n",
    "dec_feat_num = enc_feat_num\n",
    "dec_feat = [dec_feat_cat, dec_feat_num]\n",
    "print(\"Features decoder: \", dec_feat)\n",
    "\"\"\"\n",
    "\n",
    "# Decoder features:\n",
    "dec_feat_cat = ['Activity', 'Resource']\n",
    "dec_feat_num = ['case_elapsed_time', 'event_elapsed_time']\n",
    "dec_feat = [dec_feat_cat, dec_feat_num]\n",
    "print(\"Features decoder: \", dec_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:42:13.198826Z",
     "iopub.status.busy": "2025-04-25T08:42:13.198746Z",
     "iopub.status.idle": "2025-04-25T08:42:13.212221Z",
     "shell.execute_reply": "2025-04-25T08:42:13.212025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set categories:  ([('Activity', 16, {'Assign seriousness': 1, 'Closed': 2, 'Create SW anomaly': 3, 'DUPLICATE': 4, 'EOS': 5, 'INVALID': 6, 'Insert ticket': 7, 'RESOLVED': 8, 'Require upgrade': 9, 'Resolve SW anomaly': 10, 'Resolve ticket': 11, 'Schedule intervention': 12, 'Take in charge ticket': 13, 'VERIFIED': 14, 'Wait': 15}), ('Resource', 24, {'EOS': 1, 'Value 1': 2, 'Value 10': 3, 'Value 11': 4, 'Value 12': 5, 'Value 13': 6, 'Value 14': 7, 'Value 15': 8, 'Value 16': 9, 'Value 17': 10, 'Value 18': 11, 'Value 19': 12, 'Value 2': 13, 'Value 20': 14, 'Value 21': 15, 'Value 22': 16, 'Value 3': 17, 'Value 4': 18, 'Value 5': 19, 'Value 6': 20, 'Value 7': 21, 'Value 8': 22, 'Value 9': 23}), ('VariantIndex', 184, {'1.0': 1, '10.0': 2, '100.0': 3, '103.0': 4, '104.0': 5, '105.0': 6, '107.0': 7, '109.0': 8, '11.0': 9, '110.0': 10, '112.0': 11, '113.0': 12, '114.0': 13, '115.0': 14, '117.0': 15, '118.0': 16, '12.0': 17, '120.0': 18, '121.0': 19, '122.0': 20, '123.0': 21, '124.0': 22, '125.0': 23, '126.0': 24, '127.0': 25, '129.0': 26, '13.0': 27, '130.0': 28, '131.0': 29, '134.0': 30, '135.0': 31, '137.0': 32, '138.0': 33, '139.0': 34, '14.0': 35, '140.0': 36, '141.0': 37, '143.0': 38, '144.0': 39, '145.0': 40, '147.0': 41, '149.0': 42, '15.0': 43, '150.0': 44, '151.0': 45, '152.0': 46, '153.0': 47, '154.0': 48, '155.0': 49, '156.0': 50, '157.0': 51, '158.0': 52, '16.0': 53, '162.0': 54, '163.0': 55, '164.0': 56, '165.0': 57, '167.0': 58, '168.0': 59, '169.0': 60, '17.0': 61, '170.0': 62, '171.0': 63, '172.0': 64, '173.0': 65, '174.0': 66, '175.0': 67, '176.0': 68, '178.0': 69, '179.0': 70, '18.0': 71, '180.0': 72, '181.0': 73, '182.0': 74, '183.0': 75, '188.0': 76, '19.0': 77, '192.0': 78, '193.0': 79, '194.0': 80, '195.0': 81, '197.0': 82, '199.0': 83, '2.0': 84, '20.0': 85, '200.0': 86, '202.0': 87, '203.0': 88, '204.0': 89, '205.0': 90, '207.0': 91, '208.0': 92, '21.0': 93, '211.0': 94, '212.0': 95, '213.0': 96, '214.0': 97, '217.0': 98, '22.0': 99, '220.0': 100, '222.0': 101, '225.0': 102, '226.0': 103, '23.0': 104, '24.0': 105, '25.0': 106, '26.0': 107, '27.0': 108, '28.0': 109, '29.0': 110, '3.0': 111, '30.0': 112, '31.0': 113, '32.0': 114, '33.0': 115, '34.0': 116, '35.0': 117, '36.0': 118, '37.0': 119, '38.0': 120, '39.0': 121, '4.0': 122, '40.0': 123, '41.0': 124, '42.0': 125, '43.0': 126, '44.0': 127, '45.0': 128, '46.0': 129, '47.0': 130, '48.0': 131, '49.0': 132, '5.0': 133, '50.0': 134, '51.0': 135, '52.0': 136, '53.0': 137, '54.0': 138, '55.0': 139, '56.0': 140, '57.0': 141, '58.0': 142, '59.0': 143, '6.0': 144, '60.0': 145, '61.0': 146, '62.0': 147, '63.0': 148, '64.0': 149, '65.0': 150, '66.0': 151, '67.0': 152, '68.0': 153, '69.0': 154, '7.0': 155, '70.0': 156, '71.0': 157, '72.0': 158, '73.0': 159, '74.0': 160, '75.0': 161, '76.0': 162, '77.0': 163, '78.0': 164, '79.0': 165, '8.0': 166, '81.0': 167, '83.0': 168, '84.0': 169, '85.0': 170, '86.0': 171, '87.0': 172, '88.0': 173, '89.0': 174, '9.0': 175, '90.0': 176, '91.0': 177, '93.0': 178, '94.0': 179, '95.0': 180, '97.0': 181, '99.0': 182, nan: 183}), ('seriousness', 3, {'EOS': 1, 'Value 1': 2}), ('customer', 370, {'EOS': 1, 'Value 1': 2, 'Value 10': 3, 'Value 100': 4, 'Value 101': 5, 'Value 102': 6, 'Value 103': 7, 'Value 104': 8, 'Value 105': 9, 'Value 106': 10, 'Value 107': 11, 'Value 108': 12, 'Value 11': 13, 'Value 110': 14, 'Value 111': 15, 'Value 112': 16, 'Value 113': 17, 'Value 114': 18, 'Value 115': 19, 'Value 116': 20, 'Value 117': 21, 'Value 118': 22, 'Value 119': 23, 'Value 12': 24, 'Value 120': 25, 'Value 121': 26, 'Value 122': 27, 'Value 123': 28, 'Value 124': 29, 'Value 125': 30, 'Value 126': 31, 'Value 127': 32, 'Value 129': 33, 'Value 13': 34, 'Value 131': 35, 'Value 132': 36, 'Value 133': 37, 'Value 134': 38, 'Value 135': 39, 'Value 136': 40, 'Value 137': 41, 'Value 138': 42, 'Value 139': 43, 'Value 14': 44, 'Value 140': 45, 'Value 141': 46, 'Value 142': 47, 'Value 143': 48, 'Value 144': 49, 'Value 145': 50, 'Value 146': 51, 'Value 147': 52, 'Value 148': 53, 'Value 149': 54, 'Value 15': 55, 'Value 150': 56, 'Value 151': 57, 'Value 152': 58, 'Value 153': 59, 'Value 154': 60, 'Value 155': 61, 'Value 156': 62, 'Value 157': 63, 'Value 158': 64, 'Value 16': 65, 'Value 160': 66, 'Value 161': 67, 'Value 162': 68, 'Value 163': 69, 'Value 164': 70, 'Value 165': 71, 'Value 166': 72, 'Value 167': 73, 'Value 168': 74, 'Value 169': 75, 'Value 17': 76, 'Value 171': 77, 'Value 172': 78, 'Value 173': 79, 'Value 174': 80, 'Value 175': 81, 'Value 176': 82, 'Value 177': 83, 'Value 178': 84, 'Value 179': 85, 'Value 18': 86, 'Value 180': 87, 'Value 181': 88, 'Value 182': 89, 'Value 183': 90, 'Value 184': 91, 'Value 185': 92, 'Value 186': 93, 'Value 187': 94, 'Value 188': 95, 'Value 189': 96, 'Value 19': 97, 'Value 190': 98, 'Value 191': 99, 'Value 192': 100, 'Value 193': 101, 'Value 194': 102, 'Value 195': 103, 'Value 196': 104, 'Value 197': 105, 'Value 198': 106, 'Value 199': 107, 'Value 2': 108, 'Value 20': 109, 'Value 200': 110, 'Value 201': 111, 'Value 202': 112, 'Value 203': 113, 'Value 204': 114, 'Value 205': 115, 'Value 206': 116, 'Value 207': 117, 'Value 208': 118, 'Value 209': 119, 'Value 21': 120, 'Value 210': 121, 'Value 211': 122, 'Value 213': 123, 'Value 214': 124, 'Value 215': 125, 'Value 216': 126, 'Value 217': 127, 'Value 218': 128, 'Value 219': 129, 'Value 22': 130, 'Value 220': 131, 'Value 221': 132, 'Value 222': 133, 'Value 223': 134, 'Value 224': 135, 'Value 225': 136, 'Value 226': 137, 'Value 227': 138, 'Value 228': 139, 'Value 229': 140, 'Value 23': 141, 'Value 230': 142, 'Value 231': 143, 'Value 232': 144, 'Value 233': 145, 'Value 234': 146, 'Value 235': 147, 'Value 236': 148, 'Value 237': 149, 'Value 238': 150, 'Value 239': 151, 'Value 24': 152, 'Value 240': 153, 'Value 241': 154, 'Value 242': 155, 'Value 243': 156, 'Value 244': 157, 'Value 245': 158, 'Value 246': 159, 'Value 247': 160, 'Value 248': 161, 'Value 249': 162, 'Value 25': 163, 'Value 250': 164, 'Value 251': 165, 'Value 252': 166, 'Value 253': 167, 'Value 254': 168, 'Value 255': 169, 'Value 256': 170, 'Value 258': 171, 'Value 259': 172, 'Value 26': 173, 'Value 260': 174, 'Value 261': 175, 'Value 262': 176, 'Value 263': 177, 'Value 264': 178, 'Value 265': 179, 'Value 266': 180, 'Value 267': 181, 'Value 268': 182, 'Value 269': 183, 'Value 27': 184, 'Value 270': 185, 'Value 271': 186, 'Value 272': 187, 'Value 273': 188, 'Value 274': 189, 'Value 275': 190, 'Value 276': 191, 'Value 277': 192, 'Value 278': 193, 'Value 279': 194, 'Value 28': 195, 'Value 280': 196, 'Value 281': 197, 'Value 282': 198, 'Value 283': 199, 'Value 284': 200, 'Value 285': 201, 'Value 286': 202, 'Value 287': 203, 'Value 288': 204, 'Value 289': 205, 'Value 29': 206, 'Value 292': 207, 'Value 293': 208, 'Value 294': 209, 'Value 296': 210, 'Value 297': 211, 'Value 298': 212, 'Value 299': 213, 'Value 3': 214, 'Value 30': 215, 'Value 300': 216, 'Value 301': 217, 'Value 302': 218, 'Value 303': 219, 'Value 304': 220, 'Value 305': 221, 'Value 306': 222, 'Value 307': 223, 'Value 308': 224, 'Value 309': 225, 'Value 31': 226, 'Value 310': 227, 'Value 311': 228, 'Value 312': 229, 'Value 313': 230, 'Value 314': 231, 'Value 315': 232, 'Value 316': 233, 'Value 317': 234, 'Value 318': 235, 'Value 319': 236, 'Value 32': 237, 'Value 320': 238, 'Value 321': 239, 'Value 322': 240, 'Value 323': 241, 'Value 324': 242, 'Value 325': 243, 'Value 326': 244, 'Value 327': 245, 'Value 328': 246, 'Value 329': 247, 'Value 33': 248, 'Value 331': 249, 'Value 332': 250, 'Value 333': 251, 'Value 334': 252, 'Value 335': 253, 'Value 336': 254, 'Value 337': 255, 'Value 338': 256, 'Value 339': 257, 'Value 34': 258, 'Value 340': 259, 'Value 342': 260, 'Value 343': 261, 'Value 344': 262, 'Value 345': 263, 'Value 346': 264, 'Value 348': 265, 'Value 349': 266, 'Value 35': 267, 'Value 350': 268, 'Value 351': 269, 'Value 352': 270, 'Value 353': 271, 'Value 356': 272, 'Value 357': 273, 'Value 36': 274, 'Value 360': 275, 'Value 361': 276, 'Value 362': 277, 'Value 363': 278, 'Value 364': 279, 'Value 365': 280, 'Value 366': 281, 'Value 367': 282, 'Value 368': 283, 'Value 369': 284, 'Value 37': 285, 'Value 370': 286, 'Value 371': 287, 'Value 374': 288, 'Value 375': 289, 'Value 376': 290, 'Value 377': 291, 'Value 379': 292, 'Value 38': 293, 'Value 380': 294, 'Value 383': 295, 'Value 384': 296, 'Value 386': 297, 'Value 388': 298, 'Value 389': 299, 'Value 39': 300, 'Value 390': 301, 'Value 393': 302, 'Value 394': 303, 'Value 396': 304, 'Value 4': 305, 'Value 40': 306, 'Value 41': 307, 'Value 42': 308, 'Value 43': 309, 'Value 44': 310, 'Value 45': 311, 'Value 46': 312, 'Value 47': 313, 'Value 48': 314, 'Value 49': 315, 'Value 5': 316, 'Value 50': 317, 'Value 51': 318, 'Value 52': 319, 'Value 53': 320, 'Value 54': 321, 'Value 55': 322, 'Value 56': 323, 'Value 57': 324, 'Value 58': 325, 'Value 59': 326, 'Value 6': 327, 'Value 60': 328, 'Value 61': 329, 'Value 62': 330, 'Value 63': 331, 'Value 64': 332, 'Value 65': 333, 'Value 66': 334, 'Value 67': 335, 'Value 68': 336, 'Value 69': 337, 'Value 7': 338, 'Value 70': 339, 'Value 71': 340, 'Value 72': 341, 'Value 73': 342, 'Value 74': 343, 'Value 75': 344, 'Value 76': 345, 'Value 77': 346, 'Value 78': 347, 'Value 79': 348, 'Value 8': 349, 'Value 80': 350, 'Value 81': 351, 'Value 82': 352, 'Value 83': 353, 'Value 85': 354, 'Value 86': 355, 'Value 87': 356, 'Value 88': 357, 'Value 89': 358, 'Value 9': 359, 'Value 90': 360, 'Value 91': 361, 'Value 92': 362, 'Value 93': 363, 'Value 94': 364, 'Value 95': 365, 'Value 96': 366, 'Value 97': 367, 'Value 98': 368, 'Value 99': 369}), ('product', 23, {'EOS': 1, 'Value 1': 2, 'Value 10': 3, 'Value 11': 4, 'Value 12': 5, 'Value 13': 6, 'Value 14': 7, 'Value 15': 8, 'Value 16': 9, 'Value 17': 10, 'Value 18': 11, 'Value 19': 12, 'Value 2': 13, 'Value 20': 14, 'Value 21': 15, 'Value 3': 16, 'Value 4': 17, 'Value 5': 18, 'Value 6': 19, 'Value 7': 20, 'Value 8': 21, 'Value 9': 22}), ('responsible_section', 9, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5, 'Value 5': 6, 'Value 6': 7, 'Value 7': 8}), ('seriousness_2', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5}), ('service_level', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5}), ('service_type', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5}), ('support_section', 8, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5, 'Value 5': 6, 'Value 6': 7}), ('workgroup', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5})], [('case_elapsed_time', 1, {}), ('event_elapsed_time', 1, {}), ('day_in_week', 1, {}), ('seconds_in_day', 1, {})])\n",
      "Encoder input features:  [['Activity', 'Resource', 'VariantIndex', 'seriousness', 'customer', 'product', 'responsible_section', 'seriousness_2', 'service_level', 'service_type', 'support_section', 'workgroup'], ['case_elapsed_time', 'event_elapsed_time', 'day_in_week', 'seconds_in_day']]\n",
      "Decoder input+output features:  [['Activity', 'Resource'], ['case_elapsed_time', 'event_elapsed_time']]\n",
      "\n",
      "\n",
      "Sequence length of decoder output:  4\n",
      "\n",
      "\n",
      "Cells hidden size:  128\n",
      "Number of LSTM layer:  4\n",
      "Dropout rate:  0.1\n",
      "\n",
      "\n",
      "Encoder number of labels for each input feature (categorical, numerical):  [[16, 24, 184, 3, 370, 23, 9, 6, 6, 6, 8, 6], [1, 1, 1, 1]]\n",
      "Encoder indices of tensors in dataset used as input:  [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [0, 1, 2, 3]]\n",
      "Embeddings encoder:  ModuleList(\n",
      "  (0): Embedding(16, 8)\n",
      "  (1): Embedding(24, 9)\n",
      "  (2): Embedding(184, 30)\n",
      "  (3): Embedding(3, 3)\n",
      "  (4): Embedding(370, 44)\n",
      "  (5): Embedding(23, 9)\n",
      "  (6): Embedding(9, 5)\n",
      "  (7-9): 3 x Embedding(6, 4)\n",
      "  (10): Embedding(8, 5)\n",
      "  (11): Embedding(6, 4)\n",
      ")\n",
      "Total embedding feature size encoder:  129\n",
      "Total numerical feature size encoder:  4\n",
      "Input feature size encoder:  133\n",
      "Encoder initialized! \n",
      "\n",
      "Decoder label values size for each categorical input feature:  [16, 24]\n",
      "Decoder label values size for each numerical input feature:  [1, 1]\n",
      "Decoder indices of tensors in dataset used as input:  [[0, 1], [0, 1]]\n",
      "Embeddings decoder:  ModuleList(\n",
      "  (0): Embedding(16, 8)\n",
      "  (1): Embedding(24, 9)\n",
      ")\n",
      "Total embedding feature size decoder:  17\n",
      "Total numerical feature size decoder:  2\n",
      "Input feature size decoder:  19\n",
      "Output feature list of dicts (featue name, feature output size) of decoder:  [{'Activity': 16, 'Resource': 24}, {'case_elapsed_time': 1, 'event_elapsed_time': 1}]\n",
      "Decoder initialized! \n",
      "\n",
      "Output feature list of dicts (featue name, tensor index in dataset) of decoder:  [{'Activity': 0, 'Resource': 1}, {'case_elapsed_time': 0, 'event_elapsed_time': 1}]\n"
     ]
    }
   ],
   "source": [
    "import model.dropout_uncertainty_enc_dec_LSTM.dropout_uncertainty_model\n",
    "importlib.reload(model.dropout_uncertainty_enc_dec_LSTM.dropout_uncertainty_model)\n",
    "from model.dropout_uncertainty_enc_dec_LSTM.dropout_uncertainty_model import DropoutUncertaintyEncoderDecoderLSTM\n",
    "\n",
    "# Prediction decoder output sequence length\n",
    "seq_len_pred = 4\n",
    "\n",
    "# Size hidden layer\n",
    "hidden_size = 128\n",
    "\n",
    "# Number of cells\n",
    "num_layers = 4\n",
    "\n",
    "# Fixed Dropout probability \n",
    "dropout = 0.1\n",
    "\n",
    "# Encoder Decoder model initialization\n",
    "model = DropoutUncertaintyEncoderDecoderLSTM(data_set_categories=helpdesk_all_categories,\n",
    "                                             enc_feat=enc_feat,\n",
    "                                             dec_feat=dec_feat,\n",
    "                                             seq_len_pred=seq_len_pred,\n",
    "                                             hidden_size=hidden_size,\n",
    "                                             num_layers=num_layers,\n",
    "                                             dropout=dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Object Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:42:13.212951Z",
     "iopub.status.busy": "2025-04-25T08:42:13.212869Z",
     "iopub.status.idle": "2025-04-25T08:42:13.214730Z",
     "shell.execute_reply": "2025-04-25T08:42:13.214554Z"
    }
   },
   "outputs": [],
   "source": [
    "import loss.losses\n",
    "importlib.reload(loss.losses)\n",
    "from loss.losses import Loss\n",
    "\n",
    "loss_obj = Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T08:42:13.215527Z",
     "iopub.status.busy": "2025-04-25T08:42:13.215367Z",
     "iopub.status.idle": "2025-04-25T10:47:46.373364Z",
     "shell.execute_reply": "2025-04-25T10:47:46.373030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n",
      "Model:  DropoutUncertaintyEncoderDecoderLSTM(\n",
      "  (embeddings_enc): ModuleList(\n",
      "    (0): Embedding(16, 8)\n",
      "    (1): Embedding(24, 9)\n",
      "    (2): Embedding(184, 30)\n",
      "    (3): Embedding(3, 3)\n",
      "    (4): Embedding(370, 44)\n",
      "    (5): Embedding(23, 9)\n",
      "    (6): Embedding(9, 5)\n",
      "    (7-9): 3 x Embedding(6, 4)\n",
      "    (10): Embedding(8, 5)\n",
      "    (11): Embedding(6, 4)\n",
      "  )\n",
      "  (encoder): DropoutUncertaintyLSTMEncoder(\n",
      "    (embeddings): ModuleList(\n",
      "      (0): Embedding(16, 8)\n",
      "      (1): Embedding(24, 9)\n",
      "      (2): Embedding(184, 30)\n",
      "      (3): Embedding(3, 3)\n",
      "      (4): Embedding(370, 44)\n",
      "      (5): Embedding(23, 9)\n",
      "      (6): Embedding(9, 5)\n",
      "      (7-9): 3 x Embedding(6, 4)\n",
      "      (10): Embedding(8, 5)\n",
      "      (11): Embedding(6, 4)\n",
      "    )\n",
      "    (first_layer): DropoutUncertaintyLSTMCell(\n",
      "      (Wi): Linear(in_features=133, out_features=128, bias=True)\n",
      "      (Ui): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (Wf): Linear(in_features=133, out_features=128, bias=True)\n",
      "      (Uf): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (Wc): Linear(in_features=133, out_features=128, bias=True)\n",
      "      (Uc): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (Wo): Linear(in_features=133, out_features=128, bias=True)\n",
      "      (Uo): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (hidden_layers): ModuleList(\n",
      "      (0-2): 3 x DropoutUncertaintyLSTMCell(\n",
      "        (Wi): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Ui): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Wf): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Uf): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Wc): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Uc): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Wo): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Uo): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (embeddings_dec): ModuleList(\n",
      "    (0): Embedding(16, 8)\n",
      "    (1): Embedding(24, 9)\n",
      "  )\n",
      "  (decoder): DropoutUncertaintyLSTMDecoder(\n",
      "    (embeddings): ModuleList(\n",
      "      (0): Embedding(16, 8)\n",
      "      (1): Embedding(24, 9)\n",
      "    )\n",
      "    (first_layer): DropoutUncertaintyLSTMCell(\n",
      "      (Wi): Linear(in_features=19, out_features=128, bias=True)\n",
      "      (Ui): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (Wf): Linear(in_features=19, out_features=128, bias=True)\n",
      "      (Uf): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (Wc): Linear(in_features=19, out_features=128, bias=True)\n",
      "      (Uc): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (Wo): Linear(in_features=19, out_features=128, bias=True)\n",
      "      (Uo): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (hidden_layers): ModuleList(\n",
      "      (0-2): 3 x DropoutUncertaintyLSTMCell(\n",
      "        (Wi): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Ui): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Wf): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Uf): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Wc): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Uc): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Wo): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (Uo): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (output_layers): ModuleDict(\n",
      "      (Activity_mean): Linear(in_features=128, out_features=16, bias=True)\n",
      "      (Activity_var): Linear(in_features=128, out_features=16, bias=True)\n",
      "      (Resource_mean): Linear(in_features=128, out_features=24, bias=True)\n",
      "      (Resource_var): Linear(in_features=128, out_features=24, bias=True)\n",
      "      (case_elapsed_time_mean): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (case_elapsed_time_var): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (event_elapsed_time_mean): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (event_elapsed_time_var): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Train Dataset:  <event_log_loader.new_event_log_loader.EventLogDataset object at 0x7f4733005a00>\n",
      "Validation Dataset:  <event_log_loader.new_event_log_loader.EventLogDataset object at 0x7f46abeae990>\n",
      "Loss object for method calling:  <loss.losses.Loss object at 0x7f46aae31af0>\n",
      "Num. feautures that follow log-normal PDF:  []\n",
      "regularization:  0.0001\n",
      "Optimizer:  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 1e-05\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler:  <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f46ab828290>\n",
      "Epochs:  100\n",
      "Mini baches:  128\n",
      "Shuffle batched dataset:  True\n",
      "Teacher forcing ratio:  0.75\n",
      "Use GradNorm:  True\n",
      "GradNorm alpha:  1.5\n",
      "GradNorm learning rate:  0.0001\n",
      "Initial GradNorm loss weights:  Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "Initial loss values:  None\n",
      "GradNorm optimizer:  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22544ab3dc684d6fa0b7575b27a89dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 8.4586\n",
      "Validation: Avg Standard Validation Loss: 8.3297\n",
      "Validation: Avg Attenuated Validation Loss: 8.0647\n",
      "Validation Loss for Scheduler: 8.3297\n",
      "saving model\n",
      "Epoch [2/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 8.4768\n",
      "Validation: Avg Standard Validation Loss: 8.3024\n",
      "Validation: Avg Attenuated Validation Loss: 8.0247\n",
      "Validation Loss for Scheduler: 8.3024\n",
      "saving model\n",
      "Epoch [3/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 8.4759\n",
      "Validation: Avg Standard Validation Loss: 8.2437\n",
      "Validation: Avg Attenuated Validation Loss: 7.9598\n",
      "Validation Loss for Scheduler: 8.2437\n",
      "saving model\n",
      "Epoch [4/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 8.4153\n",
      "Validation: Avg Standard Validation Loss: 8.0835\n",
      "Validation: Avg Attenuated Validation Loss: 7.7525\n",
      "Validation Loss for Scheduler: 8.0835\n",
      "saving model\n",
      "Epoch [5/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 7.5283\n",
      "Validation: Avg Standard Validation Loss: 6.9771\n",
      "Validation: Avg Attenuated Validation Loss: 6.2878\n",
      "Validation Loss for Scheduler: 6.9771\n",
      "saving model\n",
      "Epoch [6/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 6.3844\n",
      "Validation: Avg Standard Validation Loss: 6.6511\n",
      "Validation: Avg Attenuated Validation Loss: 5.7473\n",
      "Validation Loss for Scheduler: 6.6511\n",
      "saving model\n",
      "Epoch [7/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 5.9199\n",
      "Validation: Avg Standard Validation Loss: 6.4521\n",
      "Validation: Avg Attenuated Validation Loss: 5.4881\n",
      "Validation Loss for Scheduler: 6.4521\n",
      "saving model\n",
      "Epoch [8/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 5.5718\n",
      "Validation: Avg Standard Validation Loss: 6.2517\n",
      "Validation: Avg Attenuated Validation Loss: 5.2677\n",
      "Validation Loss for Scheduler: 6.2517\n",
      "saving model\n",
      "Epoch [9/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 5.2688\n",
      "Validation: Avg Standard Validation Loss: 6.0364\n",
      "Validation: Avg Attenuated Validation Loss: 4.9930\n",
      "Validation Loss for Scheduler: 6.0364\n",
      "saving model\n",
      "Epoch [10/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 5.0028\n",
      "Validation: Avg Standard Validation Loss: 5.8200\n",
      "Validation: Avg Attenuated Validation Loss: 4.7392\n",
      "Validation Loss for Scheduler: 5.8200\n",
      "saving model\n",
      "Epoch [11/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 4.7435\n",
      "Validation: Avg Standard Validation Loss: 5.5006\n",
      "Validation: Avg Attenuated Validation Loss: 4.4086\n",
      "Validation Loss for Scheduler: 5.5006\n",
      "saving model\n",
      "Epoch [12/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 4.5023\n",
      "Validation: Avg Standard Validation Loss: 5.2374\n",
      "Validation: Avg Attenuated Validation Loss: 4.1368\n",
      "Validation Loss for Scheduler: 5.2374\n",
      "saving model\n",
      "Epoch [13/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 4.2834\n",
      "Validation: Avg Standard Validation Loss: 5.0631\n",
      "Validation: Avg Attenuated Validation Loss: 3.9545\n",
      "Validation Loss for Scheduler: 5.0631\n",
      "saving model\n",
      "Epoch [14/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 4.1139\n",
      "Validation: Avg Standard Validation Loss: 4.9432\n",
      "Validation: Avg Attenuated Validation Loss: 3.8186\n",
      "Validation Loss for Scheduler: 4.9432\n",
      "saving model\n",
      "Epoch [15/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 3.9452\n",
      "Validation: Avg Standard Validation Loss: 4.7954\n",
      "Validation: Avg Attenuated Validation Loss: 3.6721\n",
      "Validation Loss for Scheduler: 4.7954\n",
      "saving model\n",
      "Epoch [16/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 3.8948\n",
      "Validation: Avg Standard Validation Loss: 4.6929\n",
      "Validation: Avg Attenuated Validation Loss: 3.5390\n",
      "Validation Loss for Scheduler: 4.6929\n",
      "saving model\n",
      "Epoch [17/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 3.7506\n",
      "Validation: Avg Standard Validation Loss: 4.6994\n",
      "Validation: Avg Attenuated Validation Loss: 3.6204\n",
      "Validation Loss for Scheduler: 4.6994\n",
      "saving model\n",
      "Epoch [18/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 3.6507\n",
      "Validation: Avg Standard Validation Loss: 4.6571\n",
      "Validation: Avg Attenuated Validation Loss: 3.6257\n",
      "Validation Loss for Scheduler: 4.6571\n",
      "saving model\n",
      "Epoch [19/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 3.5906\n",
      "Validation: Avg Standard Validation Loss: 4.6642\n",
      "Validation: Avg Attenuated Validation Loss: 3.6986\n",
      "Validation Loss for Scheduler: 4.6642\n",
      "saving model\n",
      "Epoch [20/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.75\n",
      "Training: Avg Attenuated Training Loss: 3.5062\n",
      "Validation: Avg Standard Validation Loss: 4.5534\n",
      "Validation: Avg Attenuated Validation Loss: 3.6308\n",
      "Validation Loss for Scheduler: 4.5534\n",
      "saving model\n",
      "Epoch [21/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.5456\n",
      "Validation: Avg Standard Validation Loss: 4.5219\n",
      "Validation: Avg Attenuated Validation Loss: 3.5552\n",
      "Validation Loss for Scheduler: 4.5219\n",
      "saving model\n",
      "Epoch [22/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.4779\n",
      "Validation: Avg Standard Validation Loss: 4.5807\n",
      "Validation: Avg Attenuated Validation Loss: 3.6878\n",
      "Validation Loss for Scheduler: 4.5807\n",
      "saving model\n",
      "Epoch [23/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.4042\n",
      "Validation: Avg Standard Validation Loss: 4.5201\n",
      "Validation: Avg Attenuated Validation Loss: 3.7881\n",
      "Validation Loss for Scheduler: 4.5201\n",
      "saving model\n",
      "Epoch [24/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.3472\n",
      "Validation: Avg Standard Validation Loss: 4.5481\n",
      "Validation: Avg Attenuated Validation Loss: 3.8917\n",
      "Validation Loss for Scheduler: 4.5481\n",
      "saving model\n",
      "Epoch [25/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.3606\n",
      "Validation: Avg Standard Validation Loss: 4.4794\n",
      "Validation: Avg Attenuated Validation Loss: 3.6804\n",
      "Validation Loss for Scheduler: 4.4794\n",
      "saving model\n",
      "Epoch [26/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.4160\n",
      "Validation: Avg Standard Validation Loss: 4.4526\n",
      "Validation: Avg Attenuated Validation Loss: 3.6629\n",
      "Validation Loss for Scheduler: 4.4526\n",
      "saving model\n",
      "Epoch [27/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.3328\n",
      "Validation: Avg Standard Validation Loss: 4.4013\n",
      "Validation: Avg Attenuated Validation Loss: 3.7647\n",
      "Validation Loss for Scheduler: 4.4013\n",
      "saving model\n",
      "Epoch [28/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.2900\n",
      "Validation: Avg Standard Validation Loss: 4.3635\n",
      "Validation: Avg Attenuated Validation Loss: 3.6865\n",
      "Validation Loss for Scheduler: 4.3635\n",
      "saving model\n",
      "Epoch [29/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.2800\n",
      "Validation: Avg Standard Validation Loss: 4.3841\n",
      "Validation: Avg Attenuated Validation Loss: 3.7009\n",
      "Validation Loss for Scheduler: 4.3841\n",
      "saving model\n",
      "Epoch [30/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.1673\n",
      "Validation: Avg Standard Validation Loss: 4.4506\n",
      "Validation: Avg Attenuated Validation Loss: 4.3070\n",
      "Validation Loss for Scheduler: 4.4506\n",
      "saving model\n",
      "Epoch [31/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.2574\n",
      "Validation: Avg Standard Validation Loss: 4.3434\n",
      "Validation: Avg Attenuated Validation Loss: 3.8224\n",
      "Validation Loss for Scheduler: 4.3434\n",
      "saving model\n",
      "Epoch [32/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.2780\n",
      "Validation: Avg Standard Validation Loss: 4.3733\n",
      "Validation: Avg Attenuated Validation Loss: 4.1404\n",
      "Validation Loss for Scheduler: 4.3733\n",
      "saving model\n",
      "Epoch [33/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.2291\n",
      "Validation: Avg Standard Validation Loss: 4.4264\n",
      "Validation: Avg Attenuated Validation Loss: 4.4547\n",
      "Validation Loss for Scheduler: 4.4264\n",
      "saving model\n",
      "Epoch [34/100], Learning Rate: 1e-05, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.1589\n",
      "Validation: Avg Standard Validation Loss: 4.3508\n",
      "Validation: Avg Attenuated Validation Loss: 4.2500\n",
      "Validation Loss for Scheduler: 4.3508\n",
      "saving model\n",
      "Epoch [35/100], Learning Rate: 1.0000000000000002e-06, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.2601\n",
      "Validation: Avg Standard Validation Loss: 4.3747\n",
      "Validation: Avg Attenuated Validation Loss: 4.2257\n",
      "Validation Loss for Scheduler: 4.3747\n",
      "saving model\n",
      "Epoch [36/100], Learning Rate: 1.0000000000000002e-06, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.2074\n",
      "Validation: Avg Standard Validation Loss: 4.3672\n",
      "Validation: Avg Attenuated Validation Loss: 4.2978\n",
      "Validation Loss for Scheduler: 4.3672\n",
      "saving model\n",
      "Epoch [37/100], Learning Rate: 1.0000000000000002e-06, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.0331\n",
      "Validation: Avg Standard Validation Loss: 4.3723\n",
      "Validation: Avg Attenuated Validation Loss: 4.4307\n",
      "Validation Loss for Scheduler: 4.3723\n",
      "saving model\n",
      "Epoch [38/100], Learning Rate: 1.0000000000000002e-07, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.3476\n",
      "Validation: Avg Standard Validation Loss: 4.3689\n",
      "Validation: Avg Attenuated Validation Loss: 4.5983\n",
      "Validation Loss for Scheduler: 4.3689\n",
      "saving model\n",
      "Epoch [39/100], Learning Rate: 1.0000000000000002e-07, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.4571\n",
      "Validation: Avg Standard Validation Loss: 4.3634\n",
      "Validation: Avg Attenuated Validation Loss: 4.4955\n",
      "Validation Loss for Scheduler: 4.3634\n",
      "saving model\n",
      "Epoch [40/100], Learning Rate: 1.0000000000000002e-07, Teacher forcing ratio: 0.72\n",
      "Training: Avg Attenuated Training Loss: 3.2409\n",
      "Validation: Avg Standard Validation Loss: 4.3647\n",
      "Validation: Avg Attenuated Validation Loss: 4.4166\n",
      "Validation Loss for Scheduler: 4.3647\n",
      "saving model\n",
      "Epoch [41/100], Learning Rate: 1.0000000000000004e-08, Teacher forcing ratio: 0.6911999999999999\n",
      "Training: Avg Attenuated Training Loss: 3.3444\n",
      "Validation: Avg Standard Validation Loss: 4.3540\n",
      "Validation: Avg Attenuated Validation Loss: 4.4192\n",
      "Validation Loss for Scheduler: 4.3540\n",
      "saving model\n",
      "Epoch [42/100], Learning Rate: 1.0000000000000004e-08, Teacher forcing ratio: 0.6911999999999999\n",
      "Training: Avg Attenuated Training Loss: 3.3364\n",
      "Validation: Avg Standard Validation Loss: 4.3169\n",
      "Validation: Avg Attenuated Validation Loss: 4.2253\n",
      "Validation Loss for Scheduler: 4.3169\n",
      "saving model\n",
      "Epoch [43/100], Learning Rate: 1.0000000000000004e-08, Teacher forcing ratio: 0.6911999999999999\n",
      "Training: Avg Attenuated Training Loss: 3.4440\n",
      "Validation: Avg Standard Validation Loss: 4.3410\n",
      "Validation: Avg Attenuated Validation Loss: 4.3648\n",
      "Validation Loss for Scheduler: 4.3410\n",
      "saving model\n",
      "Epoch [44/100], Learning Rate: 1.0000000000000004e-08, Teacher forcing ratio: 0.6911999999999999\n",
      "Training: Avg Attenuated Training Loss: 3.2627\n",
      "Validation: Avg Standard Validation Loss: 4.3948\n",
      "Validation: Avg Attenuated Validation Loss: 4.4766\n",
      "Validation Loss for Scheduler: 4.3948\n",
      "saving model\n",
      "Epoch [45/100], Learning Rate: 1.0000000000000004e-08, Teacher forcing ratio: 0.6911999999999999\n",
      "Training: Avg Attenuated Training Loss: 3.1648\n",
      "Validation: Avg Standard Validation Loss: 4.3992\n",
      "Validation: Avg Attenuated Validation Loss: 4.4772\n",
      "Validation Loss for Scheduler: 4.3992\n",
      "saving model\n",
      "Epoch [46/100], Learning Rate: 1.0000000000000004e-08, Teacher forcing ratio: 0.6911999999999999\n",
      "Training: Avg Attenuated Training Loss: 3.2243\n",
      "Validation: Avg Standard Validation Loss: 4.3602\n",
      "Validation: Avg Attenuated Validation Loss: 4.4050\n",
      "Validation Loss for Scheduler: 4.3602\n",
      "saving model\n",
      "Epoch [47/100], Learning Rate: 1.0000000000000004e-08, Teacher forcing ratio: 0.6911999999999999\n",
      "Training: Avg Attenuated Training Loss: 3.2029\n",
      "Validation: Avg Standard Validation Loss: 4.3197\n",
      "Validation: Avg Attenuated Validation Loss: 4.2813\n",
      "Validation Loss for Scheduler: 4.3197\n",
      "saving model\n",
      "Epoch [48/100], Learning Rate: 1.0000000000000004e-08, Teacher forcing ratio: 0.6911999999999999\n",
      "Training: Avg Attenuated Training Loss: 3.2909\n",
      "Validation: Avg Standard Validation Loss: 4.3661\n",
      "Validation: Avg Attenuated Validation Loss: 4.3370\n",
      "Validation Loss for Scheduler: 4.3661\n",
      "saving model\n",
      "Epoch [49/100], Learning Rate: 1.0000000000000004e-08, Teacher forcing ratio: 0.6911999999999999\n",
      "Training: Avg Attenuated Training Loss: 3.4914\n",
      "Validation: Avg Standard Validation Loss: 4.3389\n",
      "Validation: Avg Attenuated Validation Loss: 4.3163\n",
      "Validation Loss for Scheduler: 4.3389\n",
      "saving model\n",
      "Epoch [50/100], Learning Rate: 1.0000000000000004e-08, Teacher forcing ratio: 0.6911999999999999\n",
      "Training: Avg Attenuated Training Loss: 3.3942\n",
      "Validation: Avg Standard Validation Loss: 4.4150\n",
      "Validation: Avg Attenuated Validation Loss: 4.4327\n",
      "Validation Loss for Scheduler: 4.4150\n",
      "saving model\n",
      "Epoch [51/100], Learning Rate: 1.0000000000000004e-08, Teacher forcing ratio: 0.6911999999999999\n",
      "Training: Avg Attenuated Training Loss: 3.0317\n",
      "Validation: Avg Standard Validation Loss: 4.3860\n",
      "Validation: Avg Attenuated Validation Loss: 4.4763\n",
      "Validation Loss for Scheduler: 4.3860\n",
      "saving model\n",
      "Epoch [52/100], Learning Rate: 1.0000000000000004e-08, Teacher forcing ratio: 0.6911999999999999\n",
      "Training: Avg Attenuated Training Loss: 3.3741\n",
      "Validation: Avg Standard Validation Loss: 4.3917\n",
      "Validation: Avg Attenuated Validation Loss: 4.4575\n",
      "Validation Loss for Scheduler: 4.3917\n",
      "saving model\n"
     ]
    }
   ],
   "source": [
    "import trainer.trainer\n",
    "importlib.reload(trainer.trainer)\n",
    "from trainer.trainer import Trainer\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(comment=\"Full_Helpdesk_grad_proactive_conf_check\")\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# lambda for L2 (weight, bias, dropout) regularization\n",
    "# regularization_term = 1e-3\n",
    "\n",
    "# Start learning rate\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate, weight_decay=0)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, min_lr=1e-10)\n",
    "\n",
    "# Epochs\n",
    "num_epochs = 100\n",
    "\n",
    "# BATCHING does not work currntly with custom implementation\n",
    "batch_size = 128\n",
    "\n",
    "# lambda for L2 (weight, bias, dropout) regularization: According to formula: 1/2N\n",
    "# regularization_term = 1.0/(2.0*batch_size)\n",
    "regularization_term = 1e-4\n",
    "\n",
    "# shuffle data\n",
    "shuffle = True\n",
    "\n",
    "# Teacher forcing: Smaller 0.5 more target events are used for next event prediction.\n",
    "teacher_forcing_ratio = 0.75\n",
    "\n",
    "optimize_values = {\"regularization_term\":regularization_term,\n",
    "                   \"optimizer\":optimizer,\n",
    "                   \"scheduler\": scheduler,\n",
    "                   \"epochs\":num_epochs,\n",
    "                   \"mini_batches\":batch_size,\n",
    "                   \"shuffle\": shuffle,\n",
    "                   \"teacher_forcing_ratio\":teacher_forcing_ratio,}\n",
    "\n",
    "# For suffix length of 5\n",
    "# suffix_data_split_value = 4\n",
    "\n",
    "# For suffix length of 3?\n",
    "suffix_data_split_value = 2\n",
    "\n",
    "# GradNorm parameter\n",
    "use_gradnorm = True\n",
    "gn_alpha = 1.5\n",
    "gn_learning_rate = 1e-4\n",
    "\n",
    "number_tasks = len(dec_feat[0]) + len(dec_feat[1])\n",
    "\n",
    "gradNorm = {\"use_gradnorm\":use_gradnorm,\n",
    "            \"number_tasks\": number_tasks,\n",
    "            \"gn_alpha\":gn_alpha,\n",
    "            \"gn_learning_rate\": gn_learning_rate}\n",
    "\n",
    "trainer = Trainer(device=device,\n",
    "                  model=model,\n",
    "                  data_train=helpdesk_train_dataset,\n",
    "                  data_val=helpdesk_val_dataset,\n",
    "                  loss_obj=loss_obj,\n",
    "                  log_normal_loss_num_feature = [],\n",
    "                  optimize_values=optimize_values,\n",
    "                  suffix_data_split_value=suffix_data_split_value,\n",
    "                  writer=writer,\n",
    "                  gradnorm_values=gradNorm,\n",
    "                  save_model_n_th_epoch = 1,\n",
    "                  saving_path = 'Helpdesk_full_grad_norm_proactive_conf_check.pkl')\n",
    "\n",
    "# Train the model:\n",
    "train_attenuated_losses, val_losses, val_attenuated_losses = trainer.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-25T10:47:46.374861Z",
     "iopub.status.busy": "2025-04-25T10:47:46.374640Z",
     "iopub.status.idle": "2025-04-25T10:47:46.631755Z",
     "shell.execute_reply": "2025-04-25T10:47:46.631439Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# After training is finished, plot the loss curves\n",
    "plt.plot(range(1, num_epochs+1), train_attenuated_losses, label='Training Attenuated Loss', color='blue')\n",
    "plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss', color='orange')\n",
    "plt.plot(range(1, num_epochs+1), val_attenuated_losses, label='Validation Attenuated Loss', color='green')\n",
    "# Labeling x and y axes\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "# Adding title\n",
    "plt.title('Training and Validation Loss Curve', fontsize=14)\n",
    "# Adding legend\n",
    "plt.legend()\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Probabilistic_Suffix_Prediction_U-ED-LSTM_-4nDU3HwC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0cad60a2014e453dbad0272789a5a646": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_18245f2c1c9642d38a6f31e2b4246c66",
        "IPY_MODEL_e493e608d4d1470ab2ab2429b6528272",
        "IPY_MODEL_0d52f4c17bec4b41bf94795bfe443636"
       ],
       "layout": "IPY_MODEL_5a90929f4ac7414bab3c128c03980f68",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0d52f4c17bec4b41bf94795bfe443636": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6cba1d6785a24b1c9ac8905a33f4734a",
       "placeholder": "",
       "style": "IPY_MODEL_945941e1696b4f179badc49f5eee60a4",
       "tabbable": null,
       "tooltip": null,
       "value": "100/100[2:05:32&lt;00:00,45.75s/it]"
      }
     },
     "18245f2c1c9642d38a6f31e2b4246c66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b1995c13c8d54c86bd945d30117bfe00",
       "placeholder": "",
       "style": "IPY_MODEL_58a2e4daf0a6448b856ca6fba0163f4e",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "58a2e4daf0a6448b856ca6fba0163f4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5a90929f4ac7414bab3c128c03980f68": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6cba1d6785a24b1c9ac8905a33f4734a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "945941e1696b4f179badc49f5eee60a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "980aaea1e2704157acfe64a70e120011": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a3e952ec033a4d1e83a28db159832e9e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b1995c13c8d54c86bd945d30117bfe00": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e493e608d4d1470ab2ab2429b6528272": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_980aaea1e2704157acfe64a70e120011",
       "max": 100,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a3e952ec033a4d1e83a28db159832e9e",
       "tabbable": null,
       "tooltip": null,
       "value": 100
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
